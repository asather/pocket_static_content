<html>
<head>
<title>Contact tracing by app: life-saving or invasion of privacy?</title>
</head>
<body>
<main>
<h1>Contact tracing by app: life-saving or invasion of privacy?</h1>
<article><div class='post-content'>
<p>For many Americans, it’s only a matter of weeks before the cell phones in their pockets start measuring how close they’ve come to COVID-19.</p>
<p>But advocates, scientists and researchers are monitoring the spread of something they deem to be important, too, and that’s how close these mobile applications come to invading privacy and encroaching on civil liberties.</p>
<p>It’s a question that’s emerged since countries around the world have started utilizing technology to help in contact tracing —&nbsp;a method of tracking the potential spread of a disease that traditionally has been tasked to public health authorities who work with infected patients directly to retrace their movements and close contacts.</p>
<p>Mobile contact-tracing applications, which use data from GPS or Bluetooth tracking to trace a person’s movement and who they’ve come into contact with, have started to catch on in the United States recently. Apple and Google have paired up to provide software to public health authorities that they claim is sensitive to user privacy and can help automate the notification of people who may have been exposed to COVID-19.</p>
<p>Their software will rely on Bluetooth, in particular, and will make it so public health authorities can make applications that exchange anonymous identifiers between users when they’re a few feet apart from one another. If one user is diagnosed with the virus and inputs it into the app, the other user’s phone will be notified that they came into contact with someone who tested positive. The public health authority that operates the app can then offer more guidance.</p>
<p>Though civil liberties experts signal they’re exceedingly happy with Apple and Google’s approach, they warn that if stakeholders aren’t careful and the public doesn’t remain vigilant, there could be a state-by-state mishmash of different applications —&nbsp;some of which could cross the line into invasive surveillance.</p>
<p>To Lyle Ungar, professor of computer and information science at the University of Pennsylvania, it comes down to one question: “How much privacy are people willing to give up for better information about who they’ve been exposed to?”</p>
<p>There’s no dispute among experts that contact tracing —&nbsp;along with testing that’s widely available —&nbsp;is one of the most important factors if governments want to safely reopen their economies and end stay-at-home orders.</p>
<p>Where disagreements emerge is when governments consider what role technology should play. Many think the use of mobile data will help alleviate the massive bureaucratic effort that tracking a fast-moving virus like COVID-19 will require.</p>
<p>“If everybody has these devices with the app running, we don’t have to rely on memory and a lot of sleuthing to figure out who we might have been exposed to or who we might have potentially infected,” said Stewart Baker, who served as assistant secretary for policy in George W. Bush’s Department of Homeland Security. “That would make tracing the infection much more efficient.”</p>
<p>Mr. Baker, who was also general counsel of the National Security Agency in the 1990s, said people are already putting trust in their governments to impact their employment and dictate how they can move about the country —&nbsp;so it’s “very odd” they’d draw the line at the government’s access to “a little bit of information about our contacts.”</p>
<p>But privacy advocates warn that the use of technology by governments and private companies could be ripe with potential overreaches, and that tracking people’s whereabouts —&nbsp;for one —&nbsp;could produce data that’d be easy to abuse.</p>
<p>Americans need to be “extra careful,” said Jennifer Granick, surveillance and cybersecurity counsel with the American Civil Liberties Union, because technology is a “force multiplier” that can take on a life of its own and create a surveillance state that’s entirely separate from the stated goals of stopping the spread of the virus.</p>
<p>Ms. Granick, like hundreds of scientists, researchers and advocates across the globe who signed onto a joint letter in April, insists that any mobile contact tracing application must be voluntary, transparent, decentralized and use Bluetooth data instead of location GPS data, if it’s a choice between the two.</p>
<p>The data that’s collected, too, must be stored only for as long as the crisis continues, and only collected to support public health goals, they say.</p>
<p><strong>Protecting privacy</strong></p>
<p>The voluntary nature of the applications —&nbsp;that people are able to choose if they want to download them and choose how they want to use them —&nbsp;is labeled by many as one of the main tenets of protecting privacy, and what stops the data collection from being a violation of Fourth Amendment rights, said Brent Skorup, a senior research fellow at the Mercatus Center at George Mason University.</p>
<p>Advocates pin this as a matter of trust in the government, and say there’s a fine line between recommendation and coercion.</p>
<p>“Public health only works when the public trusts the public health system, and as soon as an app like this becomes involuntary or coercive, that diminishes trust in the system and the effectiveness of public health,” said Adam Schwartz, senior staff attorney at the Electronic Frontier Foundation. “As long as we’ve had public health systems, people have evaded them.”</p>
<p>Others, like Mr. Baker, fear that making the apps voluntary will incentivize users to reap the benefits —&nbsp;staying informed about their proximity to COVID —&nbsp;then decide not to share with public health authorities if they actually test positive. To Mr. Baker, that’s a fault in the design by Apple and Google, he said.</p>
<p>Noting that they put privacy at the “forefront” of the technology’s design, Google and Apple say that when users download applications utilizing their software, they’ll have control over when to turn it off, the data they want to share and “the decision to share it,” according to guidance released by the companies.</p>
<p>The system does not collect location data, doesn’t share the identities of users to one another and is only to be used for contact tracing —&nbsp;software that will be disabled “when it is no longer needed,” the guidance says.</p>
<p>“Access to the technology will be granted only to public health authorities,” the companies say. “Their apps must meet specific criteria around privacy, security, and data control.”</p>
<p>For privacy advocates, it’s not so much a concern about Apple and Google’s effort, but with states choosing to use other softwares that don’t offer the same protections.</p>
<p>Ms. Granick, who helped found Stanford Law School’s Center for Internet and Society, said the fear is that data in some states would end up in the hands of advertisers, the police or immigration enforcement.</p>
<p>State governments must answer what they’ll do with the info, if it can be used against people and who can access it exactly, Mr. Ungar added.</p>
<p>Pennsylvania officials are having discussions with tech companies about using applications to track people’s whereabouts, Secretary of Health Rachel Levine said this past week —&nbsp;insisting that any app would be voluntary.</p>
<p>The state’s website says the government is looking at Bluetooth proximity exposure notification technology, which happens to be the software that Apple and Google are providing to public health authorities worldwide.</p>
<p>Privacy experts are encouraging governments to stay away from using location data that relies on GPS, for one because it’s not granular enough to determine whether people have come into close contact, but two, because it can place an individual on a map and show everywhere they’ve been in a day —&nbsp;whether that’s to a criminal defense lawyer, a doctor or other “super sensitive information,” said Mr. Schwartz.</p>
<p>Revealing someone’s location data can reveal perfectly legitimate activities that people just don’t want to share, said Lorrie Cranor, professor of Computer Science and of Engineering and Public Policy at Carnegie Mellon University.</p>
<p>Proximity data gathered by Bluetooth is less sensitive, advocates say, because it doesn’t consider where people are, but that they were near each other. Mr. Schwartz’s foundation is not “entirely opposed” to this, he said, though it could technically reveal if someone was in contact with, say, a union organizer or psychiatrist.</p>
<p>ACLU officials, too, question whether Bluetooth is precise enough to determine close contacts, given that signal strength and range can vary, they wrote in a paper in April.</p>
<p>Mr. Schwartz said any software should be transparent, with an open source code made available so independent computer scientists can identify bugs that could create privacy risks. Privacy advocates also say software should be decentralized, where information is stored in users’ phones and only shared with public health authorities on a case-by-case basis, voluntarily.</p>
<p>But those who worry about data getting into the wrong hands, Mr. Baker said, are overreacting. He noted that at most, it’ll be three weeks of data storage, protected with encryption at many stages —&nbsp;and when it’s not encrypted, it’s in the hands of public health authorities who are obligated to use it for noble purposes.</p>
<p>Mr. Baker worries that Apple and Google created a design that raises “far too many barriers in effectively tracking infections,” but noted that they’ve been a bit more flexible lately to those who share his point of view. The companies’ original framework, he said, was to operate their apps without government intervention at any stage. Now, public health authorities can access proximity data if a user consents to sharing.</p>
<p><strong>Charting their course</strong></p>
<p>Tech companies can largely chart their own course here, Ms. Cranor said, unless they’re challenged by the public or a government entity. Mr. Ungar has contacts in the companies —&nbsp;former students —&nbsp;who he insists are concerned about privacy and “do not want to put in place something that could later be used by an authoritarian regime,” he said.</p>
<p>Using the applications to enforce quarantines would be an example of overreach, Ms. Granick said, but Apple and Google’s model is designed so that information is not really useful for law enforcement.</p>
<p>“[The decentralised information] is well anonymized, so when it is uploaded to public health servers, you cannot readily deduce from it who was near whom at a point in time,” Ms. Granick said.</p>
<p>States now will have to decide how or if they’ll utilize the technology, while the federal government could —&nbsp;as a practical matter —&nbsp;recommend one application, Mr. Baker said.</p>
<p>Ms. Granick said no matter what, any use of technology will have to complement a significant manual contact tracing effort, because stakeholders aren’t sure if the technology will work and if people will participate. She also noted that many Americans don’t have smartphones and data plans capable of running these apps.</p>
<p>Ms. Cranor said she knows firsthand why the human element of contact tracing is so important. There were two times she may have come into contact with someone who was infected, she said, and received a phone call from someone at her university.</p>
<p>“I imagine if my app lights up one day and just says, ‘you might be at risk,’ I wouldn’t have anybody to ask questions to,” Ms. Cranor said.</p>
<p>Mary Catherine Roper, deputy legal director at the ACLU of Pennsylvania, said governments shouldn’t offer applications to the citizenry without making the case that they can provide a “real, observable, measurable aid to the public health work.”</p>
<p>Ms. Roper warns that an application could give people a false sense of security and convince them to “relax their vigilance on the things that actually stop the spread because they’ve got an app on their phone” —&nbsp;which has its limitations in that without universal testing, users’ knowledge of whether they’re infected is only a question of how recently they’ve been tested.</p>
<p>“The theoretical benefits of it are really compromised by the shortcomings,” Ms. Roper said, “and particularly, I think in the absence of universal testing and retesting, it really doesn’t offer the security anybody thinks it might be offering.”</p>
<p><em>Julian Routh: jrouth@post-gazette.com, 412-263-1952, Twitter @julianrouth.</em></p>
</div></article>
</main>
</body>
</html>
<original_url>https://www.post-gazette.com/news/corona2020/2020/05/10/Contact-tracing-by-app-life-saving-or-invasion-of-privacy/stories/202005100052</original_url>