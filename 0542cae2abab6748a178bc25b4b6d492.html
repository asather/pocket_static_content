<html>
<head>
<title>Gene Therapy: CMU making progress with its Center for Informed Democracy</title>
</head>
<body>
<main>
<h1>Gene Therapy: CMU making progress with its Center for Informed Democracy</h1>
<article><div class='post-content'>
<p>Most of 10 months have passed since Carnegie Mellon University announced it had been awarded a $5 million grant to study the toxic impact of disinformation, misinformation, and other digital skullduggery in the poisoning of our elections, a challenge that only grows more treacherous each day.</p>
<p>Not that it wasn’t demonically complicated to begin with.</p>
<p>CMU then selected the decorated researcher Kathleen Carley (MIT, Harvard, CMU since ’84) to head the Center for Informed Democracy, a pretty lofty attempt at political literacy in a country where plenty of voters think Nancy Pelosi was the cousin with the speech impediment on Laverne &amp; Shirley.</p>
<p>Undeterred, CMU made its formal name the Center for Informed Democracy and Social Cybersecurity and went to the School of Computer Science’s Institute for Software Research for Professor Carley, who like most of the country’s leading academics, have way, way better things to do than talk to me. Yet late this week, she too was undeterred.</p>
<p>My basic purpose in reaching her was to have a serious researcher answer a question that is probably too broad for serious researchers, but sometimes it’s illuminating when they take a whack at one anyway. The question was, “Given the best available knowledge about how misleading and just flat wrong information spreads on social media, are we losing this decisive battle to present the correct, relevant information in the run-up to the election?”</p>
<p>“That’s a hard question to answer,” said Ms. Carley, who has a doctorate in sociology. “It’s very clear that there is more disinformation and misinformation right now on social media and on the Internet than there ever has been, and it’s very clear that we are not making progress in educating the general public and the policy makers on how to discern what is accurate from what is inaccurate.”</p>
<p>While that might sound a lot like a yes (we’re losing and probably badly), as I said, it’s complicated.</p>
<p>The theory behind the John S. and James L. Knight Foundation grant, part of a larger foundation initiative that funds research into technology’s impact on democracy at 10 other universities as well, has to be that our best minds can imagine and implement the necessary digital dynamics to outrun the sinister forces at work in cyberspace.</p>
<p>CMU alone has enough interdisciplinary experts in network analysis, machine learning, and natural language processing to recognize how bad information is being spread; it has psychologists, sociologists, and philosophers (you heard me) to analyze the individual and group responses; it has public policy researchers to analyze government responses.</p>
<p>But is that enough? Does the other side have philosophers too?</p>
<p>“First, I would say that you don’t have to be particularly smart to spread disinformation,” she said. “A lot of this stuff is spread by those who mean well but don’t realize it isn’t true, which we often refer to as misinformation. I would be surprised if the propaganda firms were consulting philosophers, but I do think they have computer scientists on board; I do believe they have social scientists on board.</p>
<p>“I also think disinformation, troll houses, troll farms, bot-creation farms, have similar kinds of techniques and individuals involved. Around the world, we know there are people from various scientific disciplines used both to create and to identify mechanisms involved and to build a campaign. Building a large, orchestrated influence campaign requires knowing a lot about the audience, knowing a lot about story lines, putting together the timing of things, knowing how all the social platforms work, expertise at building the technology across those different platforms, exploiting their weaknesses; there’s just a lot involved with that.”</p>
<p>CMU’s efforts in this area had just started gaining successes within its detection algorithms when the pandemic hit, but Ms. Carley’s been encouraged not only that the researchers made significant progress along the track of its original intent, but as the pandemic became irretrievably entangled in the election – it’s practically a one-issue show now for the balance of the campaigns – social media predictably absorbed its own virus, the pandumbic.</p>
<p>All kinds of mis-, dis-, and mal-information has spread across the Internet about COVID-19 from all kinds of sources, including the White House briefing room.</p>
<p>Given the piggy-backing of one seemingly intractable problem onto another, you almost have to wonder if the country has lost its ability to manage an election in the face of both.</p>
<p>“I don’t think it has lost control,” Ms. Carley said. “It’s still very much an American process, but I think you just have many other factors in play, that were not evident, and were not possible, say, a decade ago.”</p>
<p>Still almost six months from the election, this column had actually planned on far more campaign commentary than it has produced, partly due to the virus but partly due to our own vast stockpile of cynicism.</p>
<p>You can analyze Trump and Biden until your fingers fall off, but I haven’t been able to escape the flippant notion that rings in my head like this: “Why am I doing this? It’s all up to the Russians anyway.”</p>
<p>I offered that to Ms. Carley as well, half hoping for a rejection.</p>
<p>“I’d say watch out for the Chinese too,” she said.</p>
<p>Gene Collier: gcollier@post-gazette.com and Twitter @genecollier.</p>
</div></article>
</main>
</body>
</html>
<original_url>https://www.post-gazette.com/opinion/gene-collier-columns/2020/05/09/Election-internet-misinformation-CMU-democracy-Gene-Collier/stories/202005090010</original_url>