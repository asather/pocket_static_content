<html>
<head>
<title>Pittsburgh suspends policing program that used algorithms to predict crime ‘hot spots’</title>
</head>
<body>
<main>
<h1>Pittsburgh suspends policing program that used algorithms to predict crime ‘hot spots’</h1>
<article><div class='post-content'>
<p>Citing concerns about potential racial bias, the city of Pittsburgh has suspended an algorithm policing program that predicted “hot spots” for criminal activity, and instead will focus any new data-driven programs on deploying social services, according to Mayor Bill Peduto.</p>
<p>The Carnegie Mellon University-developed tool aimed to rely on data sources to predict where crime would occur and then dispatch patrols to those areas. The city began piloting the program in 2017.</p>
<p>The city has&nbsp;“no plans to restart it at this time,” Mr. Peduto wrote in a letter last week to&nbsp;the Pittsburgh Task Force on Public Algorithms, hosted by the University of Pittsburgh’s Institute for Cyber Law, Policy and Security.</p>
<p>The exact date on which the city public safety officials halted the program and the extent to which they used it previously are unclear.</p>
<p>Public safety officials referred all questions to the mayor’s office.&nbsp;</p>
<p>In a letter to the Peduto administration, the task force commended the decision to pause the program, and criticized the lack of transparency and public engagement around the use of the algorithm.</p>
<p>“We understand that the decision to adopt the tool in the first instance may have been based on a demonstrated lack of racial bias and promising findings of impact that have not been shared with the public,” the June 17 letter read. “However, without transparency and public consultation, this program will not and should not achieve meaningful legitimacy.”</p>
<p>Mr. Peduto pointed the task force to his administration’s new Office of Community Health and Safety as well as the creation of a <a href="https://www.post-gazette.com/news/crime-courts/2020/06/17/Pittsburgh-mayor-Bill-Peduto-names-police-reform-task-force-police-social-justice/stories/202006170107" target="_blank">Community Task Force on Police Reform</a>.</p>
<p>“ ‘Hot Spots’ may benefit from the aid of a social worker, service provider or outreach team, not traditional policing,” the mayor wrote.</p>
<p>The project was a partnership between CMU and the Pittsburgh Bureau of Police, the Pittsburgh Department of Innovation and Performance, and the Pittsburgh Department of Public Safety, according to a statement from CMU’s Metro21: Smart Cities Institute.</p>
<p>“The goal of the project was to reduce serious violent crime in Pittsburgh through prevention without increasing arrests by predicting locations — not individuals — at heightened risk of violent crime. Police patrol activity was then directed to those locations. The project was run citywide and included all Pittsburgh neighborhoods. The project concluded in December 2019, and we are no longer sharing data with the police,” CMU’s statement said.</p>
<p>The model “did not use racial, demographic or socioeconomic data. Nor did it use data on individual persons. The model only used crime offense data for crimes with victims and 911 calls for service. Using this information, CMU researchers identified chronic hot spots based on the number of serious crimes committed in an area using data from previous years,” according to the CMU statement.</p>
<p><em>Here are the letters between Mayor Bill Peduto and the Pittsburgh Task Force on Public Algorithms:</em></p>
<p>It cited a drop in crime during the program, but also only four arrests during 20,000 hot spot patrols.</p>
<p>In January, Pitt officials&nbsp;<a href="https://www.post-gazette.com/news/social-services/2020/01/22/Pitt-task-force-examine-algorithms-local-government-possible-bias/stories/202001200064?cid=search" target="_blank">announced they would form the Pittsburgh Task Force on Public Algorithms</a>, which would examine algorithms used by local governments in human service and criminal justice settings for potential bias.</p>
<p>The group aimed “to ensure that historical discrimination and existing inequities are not reinforced,” in government algorithms, said David Hickton, Pitt Cyber founding director and task force chairman, in a statement announcing its formation.</p>
<p>The “hot spot” tool was one of several algorithms the task force said it would examine. The group has said it plans to publish its findings and a full report of nonbinding recommendations next year.</p>
<p>Task force members hosted one public meeting in March, before meetings had to be halted as part of precautions to halt the spread of COVID-19, and <a href="https://www.post-gazette.com/news/crime-courts/2020/03/16/algorithms-criminal-justice-crime-predictors-Pitt-Cyber-Law-human-rights-potential-bias/stories/202003190005?cid=search" target="_blank">those in attendance at the meeting expressed concerns about algorithms used in policing and criminal justice settings</a>.</p>
<p>A 2018 research paper on the “hot spot” program noted “even a small amount of effort and resources invested in such a program can lead to measurable and practically significant reductions in crime,” though it also noted additional study was needed.</p>
<p>“Predictive analytics for policing is an emerging field, and more empirical studies are needed to understand the potential impacts on crime volume and other citizen outcomes from hot spot programs of different scales and across cities. ... Additional work is critical for understanding which areas and communities are not adequately represented in reported crime data.&nbsp;Further research is also needed to identify what patrol activities and strategies are most effective at reducing crime and fostering goodwill among the communities being policed. Ultimately, designing a predictive policing system that is both transparent and equitable is essential for acquiring long-term support from within the police community and the general public,” the researchers concluded.</p>
<p>Chris Deluzio, policy director for Pitt Cyber and a task force member, said the group’s concern was two-fold — the use of the algorithm could replicate any existing pattern of bias, and the lack of transparency around its use.</p>
<p>There should be a public process around the use of any policing algorithm, Mr. Deluzio said.</p>
<p>“That hasn’t happened here,” he said.</p>
<p>The task force said it would also examine algorithms used in bail decisions, as well as those used by the <a href="https://www.post-gazette.com/news/social-services/2019/05/06/Allegheny-Family-Screening-Tool-County-DHS-children-child-welfare-safety/stories/201905020120" target="_blank">county’s Department of Human Services in child welfare decisions</a>.</p>
<p>More information about the task force, and an ability to submit comments are available at <a href="https://www.cyber.pitt.edu/algorithms" target="_blank">https://www.cyber.pitt.edu/algorithms</a>.</p>
<p><em>Ashley Murray: <a href="/" target="_blank">amurray@post-gazette.com</a>. Kate Giammarise: <a href="/" target="_blank">kgiammarise@post-gazette.com</a>.</em></p>
</div></article>
</main>
</body>
</html>
<original_url>https://www.post-gazette.com/news/crime-courts/2020/06/23/Pittsburgh-suspends-policing-police-program-algorithms-predict-predictive-hot-spots-crime-data/stories/202006230059</original_url>