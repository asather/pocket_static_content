<html>
<head>
<title>As Washington takes aim at Big Tech's liability shield, a fight over political motivations</title>
</head>
<body>
<main>
<h1>As Washington takes aim at Big Tech's liability shield, a fight over political motivations</h1>
<article><div class='post-content'>
<p>WASHINGTON — More than two decades after a 26-word statute allowed tech companies and social media to flourish, Republicans and Democrats are united in their desire to rewrite the&nbsp;consequential law to hold internet publishers&nbsp;accountable for what is posted on their platforms.</p>
<p>The question is whether there is any common ground to be found.&nbsp;Although the Trump administration and House Democrats want to reform the law in similar ways, they have different motivations.</p>
<p>The statute in question —&nbsp;Section 230 of the Communications Decency Act of 1996 — provides broad legal immunity to publishers of user-generated content, while also encouraging those publishers to moderate discussions and develop systems to flag inappropriate or illegal activity.&nbsp;</p>
<p>Section 230 has been widely credited with creating the internet and held up as the most important law protecting internet speech. Even critics in Congress acknowledge they have no plans to repeal it entirely.</p>
<p>But in recent years, it has been among the targets of <a href="https://www.post-gazette.com/news/politics-nation/2020/08/02/Facebook-Google-Amazon-Apple-Mike-Doyle-Judiciary-Committee-hearing/stories/202008020002?cid=search" target="_blank">rising bipartisan anger on Capitol Hill at big technology firms</a> that have come to rule everyday American society — especially since the COVID-19 pandemic increased reliance on online shopping and turned workplaces into virtual offices.</p>
<p>Facebook, Google and Twitter have failed to remove, regulate or tamp down hate speech, fake news and illegal activity on their sites. The same legal shield granted to the largest platforms also is enjoyed by online forums dedicated to message boards populated by racist manifestos that precede or encourage real-life violence, like the 2018 Tree of Life massacre in Squirrel Hill.</p>
<p>President Donald Trump entered the fray this spring after Twitter began flagging some of his tweets as harmful content that violated community standards. Twitter attached the label of “glorifying violence” to the president’s message that “when the looting starts, the shooting starts,” directed to&nbsp;the protests that erupted after the police killing of George Floyd in Minneapolis.&nbsp;&nbsp;</p>
<p>Mr. Trump, who had long accused the tech giants of censoring conservatives by fact-checking them or removing their posts, signed an executive order in May that challenged Section 230’s liability shield.&nbsp;</p>
<p>On Sept. 23, the U.S. Justice Department followed through by submitting a proposal to Congress to weaken Section 230, which Attorney General William Barr stated had allowed online platforms to “operate with impunity.”&nbsp;</p>
<p>Mr. Barr, in the statement, urged lawmakers to make reforms that allow online platforms to be sued “when they unlawfully censor speech and when they knowingly facilitate criminal activity online.”</p>
<p>The department portrayed its proposal as furthering the law’s original goal of providing liability protection to encourage good behavior online. But&nbsp;Section 230 also should not shield&nbsp;platforms that “moderate content in bad faith,” the department said.&nbsp;</p>
<p><strong>At the start</strong></p>
<p>The law was intended to resolve legal uncertainty after a pair of conflicting rulings in online defamation cases in the 1990s. Those cases effectively discouraged companies from moderating user-posted content at all after one platform was found liable for a defamatory post because it tried to referee its website but missed the harmful post.</p>
<p>Section 230 was written to be a shield for companies to create their own guidelines and moderate how they see fit: “No provider or user of an interactive computer service shall be treated as the publisher or speaker of any information provided by another information content provider,” it stated.</p>
<p>By opening up sites to defamation lawsuits, the department’s proposal would make it riskier for websites and apps to remove content they deem objectionable.</p>
<p>Republicans messaged the proposal to conservative audiences. Rep. Guy Reschenthaler, R-Peters, a freshman member of the House Republican leadership circle, took to Fox Business last month to argue Section 230&nbsp;“should go away.”</p>
<p>“The tech industry has to decide which way they want it — if they want to be platforms where they are immune from liability from defamation and slander, or if they’re to be treated like publishers, as if they’re a newspaper company,” Mr. Reschenthaler said.&nbsp;“They can’t have it both ways.”</p>
<p>Reached for comment Thursday, Mr. Reschenthaler said, “platforms like Twitter continue to abuse their power over the flow of information by discriminating against and silencing conservative viewpoints.”</p>
<p>Yet Democrats say much of the content being removed is genuinely harmful content: hate speech, disinformation intended to sow confusion ahead of elections and conspiracy theories.</p>
<p>Much of the responsibility to come up with a compromise will fall to Rep. Mike Doyle, D-Forest Hills, who sits on the House Energy and Commerce Committee and chairs its subcommittee on communications and technology issues.</p>
<p>Mr. Doyle has<a href="https://www.post-gazette.com/news/politics-nation/2020/06/24/Mike-Doyle-Trump-Twitter-Facebook-online-disinformation-COVID-19/stories/202006240085?cid=search" target="_blank"> already thrown cold water</a> on Mr. Trump’s demand to rewrite Section 230, which he said in June will&nbsp;“bully social media companies into inaction.”&nbsp;He has said Twitter was correct to flag Mr. Trump’s tweets and that reforming the law was necessary to further address such content, which he said is fueled by algorithms that reward companies with profits while promoting incendiary content.</p>
<p>In October 2019, Mr. Doyle convened a hearing that discussed <a href="https://www.post-gazette.com/news/politics-nation/2019/10/16/Congress-internet-big-tech-hate-speech-Mike-Doyle-reddit-google-youtube/stories/201910170040" target="_blank">the law’s approach to hate speec</a>h, fake news and illegal activity, pointing to the Tree of Life suspect’s violent and anti-Semitic messages online that had preceded the synagogue shooting by two years.&nbsp;In June 2020, Mr. Doyle held another hearing involving the law, entitled “A Country in Crisis: How Disinformation Online is Dividing the Nation.”</p>
<p>“We need to somehow have a policy that, on the one hand, stops this plethora of misinformation and disinformation,”&nbsp;Mr. Doyle said in an interview last week. “On the other hand, we have to do it in a way that doesn’t stifle innovation and free speech.”</p>
<p>“It’s funny Section 230 that is being attacked by the left and the right for very different reasons,” Mr. Doyle added. “This is something that’s not going to go away. It’s going to come up again in the next Congress.”</p>
<p><em>Daniel Moore: dmoore@post-gazette.com, Twitter @PGdanielmoore</em></p>
<p>&nbsp;</p>
</div></article>
</main>
</body>
</html>
<original_url>https://www.post-gazette.com/news/insight/2020/10/04/Mike-Doyle-Donald-Trump-Twitter-Section-230-Big-Tech-Silicon-Valley/stories/202010010026</original_url>